{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00igNhksq_d6",
   "metadata": {
    "id": "00igNhksq_d6"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# If you are on Google Colab, this sets up everything needed.\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "wget -O requirements.txt https://github.com/NEU-Silicon-Valley/CS7150-CA1/blob/main/requirements.txt\n",
    "pip install -r requirements.txt\n",
    "# If you are not on Google Colab, you can run these pip requirements on your own command-line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8dbff",
   "metadata": {
    "id": "2dd8dbff"
   },
   "source": [
    "# Homework 1.1: Foundations, and How to Code in Pytorch\n",
    "\n",
    "## Learning Objective\n",
    "\n",
    "The goal of this homework is to get you familar with some of the foundational mathematical and programming tools used in deep learning, so we will review a little bit of calculus and linear algebra and introduce you to the pytorch API.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You may already be familiar with pytorch, and if so, great - dive in to answer the questions below.\n",
    "\n",
    "If you are new to pytorch, your first step is to get the necessary background.  **Read and work through the notebooks in the [David's tips on how to read pytorch](https://github.com/davidbau/how-to-read-pytorch) series**, which will give you an overview of GPU usage, Autograd, optimizer classes, torch Modules, and data loading.  (Don't hand in those notebooks; no points for working through those other notebooks, though they are highly recommended and will be helpful for learning to answer the questions in the current notebook.) Hand in this current notebook completed.\n",
    "\n",
    "## Readings\n",
    "\n",
    "The following readings are not necessary to do this notebook, but you may find them interesting if you want to develop your sense for the origins of some of the important ideas in deep networks.\n",
    "\n",
    "The practice of modeling a neural network as a computational object was pioneered in this classic paper by Warren McCulloch and Walter Pitts, and we will follow along with some of their constructions envisioning neural networks as graphs that can implement logic:\n",
    "\n",
    "<a href=\"https://papers.baulab.info/McCullochPitts-1943.pdf\">Warren S. McCulloch and Walter Pitts,\n",
    "<em>A Logical Calculus of the Ideas Immanent in Nervous Activity</em>, 1943.\n",
    "</a>\n",
    "\n",
    "Pytorch is pretty new, but its modular architecture has a long history, with roots in the torch project, which is itself based on the ideas in this paper:\n",
    "\n",
    "<a href=\"https://papers.baulab.info/Bottou-1990.pdf\">LÃ©on Bottou and Patrick Gallinari,\n",
    "<em>A Framework for the Cooperation of Learning Algorithms</em>, 1990.\n",
    "</a>\n",
    "\n",
    "We will talk about the cross-entropy loss.  The use of cross-entropy loss for neural network training has its roots root in the late-1980s realization that often the units of measurement that should be used by neural networks are units of probability, not only because of its elegance, but also its excellent performance.\n",
    "\n",
    "<a href=\"https://papers.baulab.info/Solla-1988.pdf\">Sarah Solla, Esther Levin and Michael Fleisher,\n",
    "<em>Accelerated Learning in Layered Neural Networks</em>, 1988.\n",
    "</a>\n",
    "\n",
    "We will play with a state-of-the-art diffusion model that was released recently.  The whole pipeline is complex, and it will take the whole semester to learn how its parts work, but a user's view of the model is descibed well in a blog post here:\n",
    "\n",
    "<a href=\"https://huggingface.co/blog/stable_diffusion\">Suraj Patil, Pedro Cuenca, Nathan Lambert and Patrick von Platen,\n",
    "<em>Stable Diffusion with Diffusers</em>, 2022.\n",
    "</a>\n",
    "\n",
    "More papers about the diffusion model are listed in that exercise.\n",
    "\n",
    "\n",
    "## Academic Integrity, Citations, and Collaborations\n",
    "\n",
    "**In all your homework, you must explicitly cite any sources (people or any materials) you consult.**\n",
    "\n",
    "In our class homework assignments, you should think about the problems yourself first before consulting outside help.  And when you do seek out help, we strongly advise you to find a fellow classmate to talk with and work together rather than copying an answer from the internet.  You will all learn much more by thinking collaboratively and explaining ideas to one another.\n",
    "\n",
    "But if you are alone and stuck and you find some really useful insight on Stack Overflow or Github or a blog or some chat channel thread on Discord, it is not cheating to use and learn from that insight <em>if you cite your sources</em>.  Learning from the internet is acceptable as long as you **do not misrepresent somebody else's work as your own**.  Include citations in your writeup text or in comments in your code.\n",
    "\n",
    "In this first exercise you will Google for a nice solution to a real problem and **make a proper citation of your source for the solution**.  In this specific problem you will only get points if you look it up and cite the source.  In general, avoid Googling and peeking at answers for homework problems, but in this problem we ask you to do it explicitly, and you should continue this practice of citing all your sources and collaborators in the future.  Linked citations are a very cool, polite, honest and useful practice in real life. In classwork, citations are *required*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92255f8",
   "metadata": {
    "id": "c92255f8"
   },
   "source": [
    "## Exercise 1.1.1: calculus review and autograd derivatives\n",
    "\n",
    "The pytorch autograd framework is usually used to compute first derivatives, but it is perfectly capable of calculating higher order partial derivatives.  In this exercise we will try it out.\n",
    "\n",
    "In the code below, a function $p_0(x) =$ `polynomial(x)` $= x^4 - 2 x^3 + 3 x^2 - 4 x + 5$ is given, and it is applied to a batch of 100 values of $x$ in the range $[-2, 3]$ given as `x = torch.linspace(-2.0, 3.0, 100)`.  The batch of 100 values of $p_0(x)$ is stored as `y`, and the results are plotted.\n",
    "\n",
    "**Question 1.1**  **Fill in the formula below.**  Understand why we suggest using gradients of `y.sum()`.\n",
    "\n",
    "If $y_i = p_0(x_i)$ and $s = \\sum_i y_i$, then the gradient $\\nabla_x s$ is a vector that has components $\\partial s / \\partial x_i$, given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial s}{\\partial x_i} = \\boxed{\\text{TODO: put your answer here}}\n",
    "$$\n",
    "\n",
    "**Question 1.2**  Fill in the code below.  To create your ground truth solutions, apply calculus by hand (just use the Power Rule) to compute the derivative of the polynomial, and put the formula in as the definition of `p1(x)`.  Plot the reults.  Do the same for `p2`, `p3` and `p4` for successive derivatives.  To plot results correctly, the results should be a batch of the same size as the input; you might need to use `torch.ones_like(x)` or `x**0` or something similar to make this work in some cases.\n",
    "\n",
    "Then make pytorch autograd do the work.  Enable gradient computations on `x` by adding the `requires_grad` flag when it is created, and then  modify the line that defines `dy_dx` to uncomment the call to `torch.autograd.grad` and make it work.  Plot the results and make sure it looks the same as `p1`. Add more calls to `torch.autograd.grad` to compute the 2nd, 3rd, and 4th derivatives, and plot the results, and make sure they look right.  The 2nd derivative should come from applying `grad` to the 1st derivative, and so on.  Take a look at the advice about higher-order gradients from the [pytorch documentation for `torch.autograd.grad`](https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803441d9",
   "metadata": {
    "id": "803441d9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def polynomial(x):\n",
    "    return x**4 - 2 * x**3 + 3 * x**2 - 4 * x + 5\n",
    "\n",
    "# MODIFY THE CODE BELOW TO DEFINE p1, p2, p3, p4 and d2y_x, d3y_x, and d4y_x\n",
    "\n",
    "def p1(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of polynomial(x)\n",
    "def p2(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of p1(x)\n",
    "def p3(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of p2(x)\n",
    "def p4(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of p3(x)\n",
    "\n",
    "x = torch.linspace(-2.0, 3.0, 100) # TODO: fix me by adding requires_grad\n",
    "y = polynomial(x)\n",
    "\n",
    "[dy_dx] = [torch.zeros_like(x)] # torch.autograd.grad(y.sum(), [x])  # TODO: fix me\n",
    "[d2y_dx] = [torch.zeros_like(x)] # TODO: fix me to be the 2st derivative of y.sum() w.r.t. to x\n",
    "[d3y_dx] = [torch.zeros_like(x)] # TODO: fix me to be the 3rd derivative of y.sum() w.r.t. to x\n",
    "[d4y_dx] = [torch.zeros_like(x)] # TODO: fix me to be the 4th of y.sum() w.r.t. to x\n",
    "\n",
    "# DO NOT CHANGE THE PLOTTING CODE OR TESTS BELOW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ax1.set_title('Power rule')\n",
    "    for i in range(0, 5):\n",
    "        ax1.plot(x, [polynomial, p1, p2, p3, p4][i](x), label=f'$p_{i}(x)$')\n",
    "    ax1.legend()\n",
    "    ax2.set_title('Autograd')\n",
    "    ax2.plot(x, y, label='$y$')\n",
    "    ax2.plot(x, dy_dx, label='$dy/dx$')\n",
    "    for i in [2, 3, 4]:\n",
    "        ax2.plot(x, [d2y_dx, d3y_dx, d4y_dx][i-2], label=f'$d^{i}y/dx$')\n",
    "    ax2.legend()\n",
    "\n",
    "assert(all((p1(x) - dy_dx).abs() < 1e-5))\n",
    "assert(all((p2(x) - d2y_dx).abs() < 1e-5))\n",
    "assert(all((p3(x) - d3y_dx).abs() < 1e-5))\n",
    "assert(all((p4(x) - d4y_dx).abs() < 1e-5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1cfbd0",
   "metadata": {
    "id": "0d1cfbd0"
   },
   "source": [
    "## Exercise 1.1.2: McCullough-Pitts Neural Networks\n",
    "\n",
    "The modern conception of artificial neural networks is essentially the same as the model originally devised by [McCullough and Pitts in their seminal 1943 paper](https://papers.baulab.info/McCullochPitts-1943.pdf).  In that work, they observed that a biological neuron could be seen as an object that adds up its inputs, possibly weighting some inputs differently from others, and then firing an output only once some threshold is reached.  This can be modeled as a weighted sum followed by a nonlinearity:\n",
    "\n",
    "<img src=\"https://github.com/NEU-Silicon-Valley/CS7150-CA1/blob/main/mp-model.png?raw=true\" width=\"800\">\n",
    "\n",
    "McCullough and Pitts reasoned about such neurons individually or in very small networks, and they asked: what is the computational power of such networks? Can they reproduce any logical computation? We will follow along with their exploration by constructing networks for the various logical operations that can be created with two binary inputs.\n",
    "\n",
    "We begin by creating a `torch.nn.Module` for the step-function nonlinearity.  We call it `Sign` because it is based on the `sign` function, returning `+1` for positive numbers and `-1` for negative numbers.   Like any torch `Module`, it will be a callable object.  We define the calling behavior in our `forward` method.   Notice that, as is typical in pytorch, our `Sign` module is designed to be able to operate on batches of data gathered in a `Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8ecda",
   "metadata": {
    "id": "f9e8ecda"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "class Sign(torch.nn.Module):\n",
    "    '''\n",
    "    The Sign nonlinearity is a step function that returns +1 for all positive\n",
    "    numbers and -1 for all negative numbers.  Zero stays as zero.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return x.sign()\n",
    "\n",
    "demo = Sign()\n",
    "x = Tensor([-3.14, 1e-6, 0.0, -0.0])\n",
    "print('Sign of', x, 'is', demo(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc80be0",
   "metadata": {
    "id": "4bc80be0"
   },
   "source": [
    "Next we implement a slightly more elaborate `torch.nn.Module` for a McCullough-Pitts neuron.\n",
    "\n",
    "The `McCulloughPittsNeuron` torch Module object computes both the weighted sum (as a `torch.nn.Linear` operation called `summation`) and the `Sign` activation nonlinearity.  The `forward` method does both steps.\n",
    "\n",
    "The `McCulloughPittsNeuron` object can take any number of inputs; the number and names of the inputs and output are configured in the constructor, and the multiple named inputs are provided to the neuron as a dictionary contaiing `Tensor`s.  They are designed to be wired together in `torch.nn.Sequential` sequences.\n",
    "\n",
    "Read the code below to see how to configure a small network of `McCulloughPittsNeuron`s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef3945",
   "metadata": {
    "id": "deef3945"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from baukit import PlotWidget, show\n",
    "\n",
    "class McCulloughPittsNeuron(torch.nn.Module):\n",
    "    '''\n",
    "    A McCullough-Pitts Neuron.  It computes a weighted sum of any number of inputs,\n",
    "    then it thresholds the output through a nonlinear activation step function.\n",
    "    It pulls named inputs from an input dictionary and puts output into the\n",
    "    dictionary.  That allows networks to be created by sequencing neurons and\n",
    "    connecting them by using dictionary names.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        net = McCulloughPittsNeuron(\n",
    "                weight_a = 0.5,\n",
    "                weight_b = -0.3,\n",
    "                weight_c = 2.0,\n",
    "                bias     = 1.0)\n",
    "        print(net(dict(\n",
    "                a=Tensor([1.0]),\n",
    "                b=Tensor([-1.0]),\n",
    "                c=Tensor([-1.0])))['out'])\n",
    "\n",
    "    The above creates a single neuron with three inputs a, b, and c plus some bias.\n",
    "    It is invoked by providing a dictionary of all the inputs as tensors.\n",
    "\n",
    "        net = torch.nn.Sequential(\n",
    "            McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, output_name='d'),\n",
    "            McCulloughPittsNeuron(weight_b=1.0, weight_d=1.0, bias=1.0),\n",
    "        )\n",
    "        print(net(dict(a=Tensor([1.0]), b=Tensor([-1.0])))['out'])\n",
    "\n",
    "    The above creates and runs a network of two neurons in this configuration:\n",
    "    ```\n",
    "             a -----> +----------+\n",
    "                      | Neuron 0 | ---> d --+\n",
    "             b ---+-> +----------+          +--> +----------+\n",
    "                  |                              | Neuron 1 | ---> out\n",
    "                  +----------------------------> +----------+\n",
    "    ```\n",
    "    As the sequence is run, the dictionary grows; after the first neuron is run,\n",
    "    the dictionary contains a, b, and d.  After the second neuron is run, the\n",
    "    final dictionary contains a, b, d, and out.\n",
    "    '''\n",
    "    def __init__(self, bias=0.0, activation=Sign, output_name='out', **kwargs):\n",
    "        '''\n",
    "        Construct a neuron by specifying any number of input weights in the arguments:\n",
    "\n",
    "            weight_a:    The weight for the 'a' input.\n",
    "                         Each `weight_x` in the constructor adds an input named 'x'.\n",
    "            bias:        The constant bias to add to the weighted sum.\n",
    "            output_name: The output name, defaults to 'out'.\n",
    "            activation:  The nonlinearity to use; defaults to the \"Sign\" step function.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # We use the pytorch Linear module with a one-dimenaional output\n",
    "        self.summation = torch.nn.Linear(len(kwargs), 1)\n",
    "        self.activation = None if activation is None else activation()\n",
    "        self.output_name = output_name\n",
    "        self.input_names = []\n",
    "        with torch.no_grad():\n",
    "            self.summation.bias[...] = bias\n",
    "            for k, v in kwargs.items():\n",
    "                assert k.startswith('weight_'), f'Bad argument {k}'\n",
    "                self.summation.weight[0, len(self.input_names)] = v\n",
    "                self.input_names.append(k[7:])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        The inputs should be a dictionary containing the expected input keys.\n",
    "        The results are computed.  Then the return value will be a copy of the\n",
    "        input dictionary, with the additional output tensor added.\n",
    "        '''\n",
    "        state = inputs.copy()\n",
    "        assert self.output_name not in state, f'Multiple {self.output_name}\\'s conflict'\n",
    "        x = torch.stack([inputs[v] for v in self.input_names], dim=1)\n",
    "        x = self.summation(x)[:,0]\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        state[self.output_name] = x\n",
    "        return state\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'input_names={self.input_names}, output_name=\\'{self.output_name}\\''\n",
    "\n",
    "def visualize_logic(nets, arg1='a', arg2='b'):\n",
    "    '''\n",
    "    Pass any number of McCullough-Pitts neurons or neural networks with two\n",
    "    inputs named 'a' and 'b', and it will visualize all of their logic, using\n",
    "    white squares to indicate +1, black squares to indicate -1, and orange\n",
    "    squares to indicate intermediate values.\n",
    "    '''\n",
    "    grid = torch.Tensor([[\n",
    "        [-1.0, 1.0],\n",
    "        [-1.0, 1.0],\n",
    "    ], [\n",
    "        [ 1.0, 1.0],\n",
    "        [-1.0,-1.0],\n",
    "    ]])\n",
    "    a, b = grid\n",
    "    def make_viz(n, case=()):\n",
    "        if isinstance(n, list):\n",
    "            return [make_viz(net, case + (str(i+1),)) for i, net in enumerate(n)]\n",
    "        def make_plot(fig):\n",
    "            with torch.no_grad():\n",
    "                out = n({arg1: a.view(-1), arg2: b.view(-1)})['out'].view(a.shape)\n",
    "            [ax] = fig.axes\n",
    "            ax.imshow(out, cmap='hot', extent=[-2,2,-2,2], vmin=-1, vmax=1)\n",
    "            ax.invert_yaxis()\n",
    "            ax.xaxis.tick_top()\n",
    "            ax.tick_params(length=0)\n",
    "            ax.set_xticks([-1, 1], [f'{arg1}=-1', f'{arg1}=1'])\n",
    "            ax.set_yticks([-1, 1], [f'{arg2}=-1', f'{arg2}=1'])\n",
    "        return [PlotWidget(make_plot, figsize=(1.1,1.1), dpi=100, bbox_inches='tight'),\n",
    "                show.style(margin='0 0 20px 45%', textAlign='right'), f'case {\" \".join(case)}']\n",
    "    show([show.WRAP, make_viz(nets)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887b7f9",
   "metadata": {
    "id": "1887b7f9"
   },
   "source": [
    "Below is an example of a two small networks using the `McCulloughPittsNeuron`:  One single-neuron network, and one two-neuron network.  The behavior of the networks on $\\pm 1$ input for `a` and `b` is visualized, with white for $+1$ output and black for $-1$; orange indicates an indecisive $0$.\n",
    "\n",
    "The networks correspond to the code below:\n",
    "\n",
    "<img src=\"https://github.com/NEU-Silicon-Valley/CS7150-CA1/blob/main/mp-examples.png?raw=true\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94828b5",
   "metadata": {
    "id": "a94828b5"
   },
   "outputs": [],
   "source": [
    "visualize_logic([\n",
    "    # First network: just one neuron.\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=0.5, bias=0.5),\n",
    "\n",
    "    # Second network: two neurons hooked together.\n",
    "    torch.nn.Sequential(\n",
    "        McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, bias=0.0, output_name='d'),\n",
    "        McCulloughPittsNeuron(weight_b=0.5, weight_d=0.5, bias=1.0),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff574af4",
   "metadata": {
    "id": "ff574af4"
   },
   "source": [
    "**Question 2.1** Use `McCulloughPittsNeuron`s to implement and visualize all the following cases.\n",
    "<img src=\"https://github.com/NEU-Silicon-Valley/CS7150-CA1/blob/main/mp-target.png?raw=true\">\n",
    "\n",
    "How many of the cases are able to be handled using a **single** neuron?  $\\boxed{\\text{TODO: fill me in}}$\n",
    "\n",
    "What are the names for the logical operations that require multiple neurons?  $\\boxed{\\text{TODO: fill me in}}$\n",
    "\n",
    "Put your code for implemeintting and visualizing each of the 4 neural networks (or single-neuron networks) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793e39a",
   "metadata": {
    "id": "b793e39a"
   },
   "outputs": [],
   "source": [
    "# Modify this to implement and vidualize the networks\n",
    "\n",
    "#visualize_logic([\n",
    "    # TODO: list your 14 networks here.\n",
    "#])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1d218",
   "metadata": {
    "id": "c2f1d218"
   },
   "source": [
    "## Exercise 1.1.3: Softmax, KL, Cross-Entropy, and Squared Error\n",
    "\n",
    "In the 1980's, researchers like [Sarah Solla](https://papers.baulab.info/Solla-1988.pdf) and [John Hopfield](https://papers.baulab.info/also/Hopfield-1987.pdf) discovered that networks are very effective when trained to model *probabilities* instead of just discrete binary logic.  Even in the case where the output should make a choice between two alternatives, it is often best to have the network output its estimate of the *probability distribution* of the choice to be made, rather than just a 0 or a 1.\n",
    "\n",
    "So in modern deep learning, we will often pursue the goal of matching some true vector of discrete probabilities $y \\in \\mathbb{R}^{n}$ by computing some model-predicted vector of probabilities $p \\in \\mathbb{R}^{n}$ that is derived from some raw neural network output $z \\in \\mathbb{R}^{n}$, and then measuring its deviation from some true distribution $y$.\n",
    "\n",
    "This problem of generating a predicted probability distribution $p$ to match some observed truth $y$ is is so central and common in deep networks that you should make sure you are very familiar with the specific clever functions that everybody uses to do it, and why this approach works so well.\n",
    "\n",
    "The modeling of $p$ and the measurement of the distance to $y$ is almost always done in the same way: **softmax** and **cross-entropy**.\n",
    "\n",
    "Here is what a the softmax-cross-entropy computation looks like, when modeling a choice between two alternatives:\n",
    "\n",
    "<img src=\"https://github.com/NEU-Silicon-Valley/CS7150-CA1/blob/main/softmax-loss.png?raw=true\" width=600>\n",
    "\n",
    "On the left we have some numbers $z$ that are computed with the intention of modeling some choices in the real world.  On the right we have a categorical probablity distribution $y$ that is the true distribution of the choices actually observed in the world.  (In our figure we have just drawn two choices, but a big model could estimate a distribution over hundreds or thousands of choices.)  In the middle, we have two steps.  First, $p$ is the result of using the \"softmax\" function to convert the arbitrarily-scaled numbers $z_i$ to nicely-scaled numbers $p_i$ between 0 and 1 that could be interpreted as a categorical probablity distribution.  Then to summarize the difference between the calculated $p$ and the true $y$, some loss $L$ is computed, where $L$ is a single number that will be small if the vectors $p$ and $y$ are close.  When working with categorical probabilities, $L$ is almost always the cross-entropy loss function, but other choices could be used.\n",
    "\n",
    "Below we introduce both the softmax and the cross-entropy (CE) loss function, and we also compare it to KullbackâLeibler (KL) divergence, as well as squared Euclidean vector distance, which is also known as the squared-error (SE) loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f240d",
   "metadata": {
    "id": "133f240d"
   },
   "source": [
    "**Question 3.1**. Jacobians and the the softmax function.\n",
    "\n",
    "The [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function) $p = \\text{softmax}(z) : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}$ is defined as:\n",
    "\n",
    "$$\\text{softmax}(z)_i = p_i = \\frac{e^{z_{i}}}{\\sum_{j} e^{z_j}}$$\n",
    "\n",
    "It is used to convert an vector of arbitrary score numbers $z$ called *logits* into a vector $p$ that is a valid categorical probability distribution.  Fill in the following:\n",
    "\n",
    "Write the simplest expression for the sum of $\\text{softmax}(z)_i$ over all $i$:\n",
    "\n",
    "$$\\sum_i p_i = \\sum_i \\frac{e^{z_{i}}}{\\sum_{j} e^{z_j}} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "The input to softmax $z$ are called *logits* because they can be through of as expressing probabilities on a logistic or log scale.  Now suppose we have some new logits $z^*$ which form a vector that is shifted from $z$ by $k$ in all dimensions, where $z^*_i = z_i + k$.  How does such a shift affect the softmax?  Work it out:\n",
    "\n",
    "Assuming we have $p = \\text{softmax}(z)$, write the simplest expression for $p^* = \\text{softmax}(z^*) = \\text{softmax}(z + k)$ in terms of only the original $p_i$ and $k$:\n",
    "\n",
    "$$p^*_{i} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "This remarkable property means that the output of softmax does not depend so much on the specific values of $z_i$, but on the differences between the $z_i$.\n",
    "\n",
    "It is useful to know the derivatives of softmax. Remember that the [Jacobian of a vector function](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) $f(z): \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{m}$ is the matrix\n",
    "\n",
    "$$\\mathbf{J}_{f}(z) = \\left[\\begin{matrix}\n",
    "\\frac{\\partial f_1}{\\partial z_1} &\n",
    "\\frac{\\partial f_1}{\\partial z_2} &\n",
    "... &\n",
    "\\frac{\\partial f_1}{\\partial z_n} \\\\\n",
    "\\frac{\\partial f_2}{\\partial z_1} &\n",
    "\\frac{\\partial f_2}{\\partial z_2} &\n",
    "... &\n",
    "\\frac{\\partial f_2}{\\partial z_n} \\\\\n",
    "\\vdots & & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial z_1} &\n",
    "\\frac{\\partial f_m}{\\partial z_2} &\n",
    "... &\n",
    "\\frac{\\partial f_m}{\\partial z_n}\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "\n",
    "Work out the Jacobian for softmax in the case where $n=2$, writing the solutions for each partial derivative $\\frac{\\partial p_i}{\\partial z_j}$.  Write each partial derivative it in the simplest form in terms of $p_i$ (and try to eliminate $z_i$).  It might be helpful to combine terms by using the fact that $p_1 + p_2$ is a constant.  Try to work it out yourself even though this problem is solved all over the web.  Remember to cite your sources if you get help on the internet or with an AI.\n",
    "\n",
    "\n",
    "$$\\mathbf{J}_{\\text{softmax}}(z) =\n",
    "\\mathbf{J}_{p}(z) =\n",
    "\\left[\\begin{matrix}\n",
    "\\frac{\\partial p_1}{\\partial z_1} &\n",
    "\\frac{\\partial p_1}{\\partial z_2} \\\\\n",
    "\\frac{\\partial p_2}{\\partial z_1} &\n",
    "\\frac{\\partial p_2}{\\partial z_2}\n",
    "\\end{matrix}\\right] =\n",
    "\\left[\\begin{matrix}\n",
    "\\boxed{\\text{TODO: fill me in}} &\n",
    "\\boxed{\\text{TODO: fill me in}} \\\\\n",
    "\\boxed{\\text{TODO: fill me in}} &\n",
    "\\boxed{\\text{TODO: fill me in}}\n",
    "\\end{matrix}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd103d",
   "metadata": {
    "id": "92bd103d"
   },
   "source": [
    "**Question 3.2**. KL divergence, Cross-entropy, and mean squared error loss.\n",
    "\n",
    "To measure and optimize the goal of matching $p$ to some true real-world distribution $y$, we will need to define some number that summarizes the difference beween $y$ and $p$.  There are several natural possibilities to quantify the difference.  Since both $y$ and $p$ are $n$-dimensional vectors, one natural choice is to look at the squared [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between the two vectors; this is known as the [**squared error** loss](https://en.wikipedia.org/wiki/Mean_squared_error):\n",
    "\n",
    "$$\\text{SE}(y, p) = || y - p ||^2 =  \\sum_{i}  (y_i - p_i)^2$$\n",
    "\n",
    "What is the value of SE if $y = p$?\n",
    "\n",
    "$$\\text{SE}(y, y) = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "What is the partial derivative of $\\text{SE}(y, p)$ with respect to the $i$th component $p_i$?  It should be possible to express the answer in terms of just $y_i$ and $p_i$.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{SE}(y, p)}{\\partial p_i} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "A different choice for comparing $y$ and $p$ is the famous **KL divergence** ([Wikipedia article here](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)) which is defined as\n",
    "\n",
    "$$\\text{KL}(y; p) = \\sum_i y_i \\log\\frac{y_i}{p_i}$$\n",
    "\n",
    "What is the value of KL divergence if $y = p$?\n",
    "\n",
    "$$\\text{KL}(y; y) = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "KL divergence can be written as the difference between entropy $\\text{H}(y)= -\\sum_i y_i \\log y_i$ and *cross-entropy* $\\text{CE}(y; p) = - \\sum_i y_i \\log p_i$ as follows:\n",
    "\n",
    "$$\\text{KL}(y; p) = \\sum_i y_i \\log y_i - \\sum_i y_i \\log p_i = \\text{CE}(y; p) - \\text{H}(y)$$\n",
    "$$\\text{CE}(y; p) = - \\sum_i y_i \\log p_i$$\n",
    "\n",
    "Since $H(y)$ is a constant that does not depend on the model outputs $p$, the shape of the cross-entropy loss is the same as the KL loss, just shifted by a constant.  In particular, when looking at derivatives of negative CE with respect to components of $p$, they are the same as derivatives of KL with respect to components of $p$.  Let us compute some of those derivatives.\n",
    "\n",
    "What is the partial derivative of $\\text{CE}(y; p)$ with respect to the $i$th component $p_i$?  It should be possible to express the answer in terms of just $y_i$ and $p_i$.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{CE}(y; p)}{\\partial p_i} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "Convince yourself that this is the same as $\\frac{\\partial \\, \\text{KL}(y; p)}{\\partial p_i}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929136a2",
   "metadata": {
    "id": "929136a2"
   },
   "source": [
    "Let's go further back from $p_i$ and understand partial derivatives with respect to $z_i$.  Remember how the [chain rule works over vector functions](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/multivariable-chain-rule-simple-version): for example if we wish to compute $\\partial L / \\partial z_1$, we must consider multiple paths, both the path through $p_1$ and the path through $p_2$.\n",
    "\n",
    "<img src=\"https://github.com/NEU-Silicon-Valley/CS7150-CA1/blob/main/two-partial-paths.png?raw=true\" width=\"420\">\n",
    "\n",
    "**Question 3.3**. Gradient of negative CE (or KL) loss on softmax, and gradient of SE loss on softmax.\n",
    "\n",
    "Using the chain rule to combine answers for 2.3 and 2.4, compute the following partial derivative of cross-entropy with respect to the first component $z_1$.  You should work to find simple expressions in terms of $p_1$ and $y_1$ instead of making a messy expression with the $z_i$.  To simplify terms, you may find it useful to remember thet $y_1 + y_2 = 1$ and $p_1 + p_2 = 1$.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{CE}(y; p)}{\\partial z_1} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "Try to work it out on your own.  If you consult the internet, please add a citation.\n",
    "\n",
    "Next, compute the analogous partial derivative of SE with repect to $z_1$.  Again, keep the expression as simple as you can, using only $y_1$ and $p_1$ if you can.  Hint: it is a polynomial that can be written as the product of three terms.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{SE}(y, p)}{\\partial z_1} = \\boxed{\\text{TODO: fill me in}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fe3d7",
   "metadata": {
    "id": "ce0fe3d7"
   },
   "source": [
    "Negative CE and SE applied to softmax have a lot of similarities, but they have some significant differences in their derivatives.\n",
    "\n",
    "Let us visualize these derivatives.\n",
    "\n",
    "Read and run the code below and interact with the widget.  It shows how the KL, CE, and SE loss vary as a function of the logits.  If you click on the CE checkbox, you can see how negative cross entropy is parallel to the KL loss curve.\n",
    "\n",
    "\n",
    "Also notice how SE is very different from KL. In particular, notice how SE loss suffers from **vanishing graidents**: it saturates in regions where the predicted answer $p$ is far from the true answer $y$.  The flatness of the SE loss means that it does not really distinguish between the quality of bad answers, and it can be hard to use SE as a guide to improve a bad answer.\n",
    "\n",
    "Also, notice that when the target probability $y$ is imbalanced, e.g., $y=0.1$, then SE is also noticably flatter than KL at the point of minimum loss, with a much flatter curvature.  That means that SE is very accepting of not-very-good answers whereas KL does a better job at distinguishing very-good answers from slightly less-good answers.\n",
    "\n",
    "**Question 3.4**. Plot and compare the partial derivatives of KL, and SE on softmax as well.\n",
    "\n",
    "In the code below, the plot on the right is incomplete because it does not include the correct plot of partial dervatives for KL and SE losses.  Copy your answers from 3.3 into the proper lines of the code below to visualize the derivatives as well.\n",
    "\n",
    "Notice that CE has exactly the same shape as KL.\n",
    "\n",
    "The plots you make explain why cross-entropy loss typically works much better than SE in practice.  While both KL and SE are flat at the optimal point, unlike KL, SE flattens out again when the logits are far from the optimal point.  We say that SE *saturates* and suffers from a *vanishing gradient* when the system is far from the optimum.  Optimizations behave like a rolling stone: if you were to put a stone on the SE loss curve, it could easily get stuck in the high flat area of the curve.  Whereas if you put a stone on the the KL loss curve, it would be on a steeper slope and roll quickly to the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab138f2e",
   "metadata": {
    "id": "ab138f2e"
   },
   "outputs": [],
   "source": [
    "from baukit import PlotWidget, Range, Checkbox, show\n",
    "import math\n",
    "\n",
    "xmin, xmax = -6.0, 6.0\n",
    "z = torch.stack([\n",
    "    torch.zeros(201),\n",
    "    torch.linspace(xmin, xmax, 201),\n",
    "])\n",
    "p = torch.softmax(z, dim=0)\n",
    "\n",
    "def compare_loss(fig, y1=0.5, dokl=True, dose=True, doce=True, dol1=True):\n",
    "    [ax1] = fig.axes\n",
    "    y0 = 1.0 - y1\n",
    "    kl = y0 * (math.log(y0) - torch.log(p[0])) + y1 * (math.log(y1) - torch.log(p[1]))\n",
    "    ce = y0 * ( - torch.log(p[0])) + y1 * ( - torch.log(p[1]))\n",
    "    se = ((p - torch.tensor([y0, y1])[:, None])**2).sum(0)\n",
    "    # sampled_se = (y0 * ((1-p[0])**2 + p[1]**2)) + (y1 * ((1-p[1])**2 + p[0]**2))\n",
    "    sampled_l1 = (2*y0*p[1] + 2*y1*p[0])\n",
    "    ax1.clear()\n",
    "    ax1.set_ylim(0, 3.0)\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Difference between logits $z_1 - z_0$')\n",
    "    ax1.set_title(f'Loss curve on softmax when target $y_1={y1:.3f}$')\n",
    "\n",
    "    if dokl: ax1.plot(z[1], kl, label='KL', color='b')\n",
    "    if dose: ax1.plot(z[1], se, label='SE', color='r')\n",
    "    if doce: ax1.plot(z[1], ce, label='CE', color='g', linestyle='dashed', alpha=0.6)\n",
    "    if dol1: ax1.plot(z[1], sampled_l1, label='L1', color='orange', linestyle='dotted', alpha=0.7)\n",
    "    if dokl or dose or doce or dol1: ax1.legend()\n",
    "\n",
    "def compare_grad(fig, y1=0.5, dokl=True, dose=True):\n",
    "    [ax1] = fig.axes\n",
    "    y0 = 1.0 - y1\n",
    "    # TODO: fill me in so that d kl / d z1 is plotted.\n",
    "    dkl_dz1 = torch.zeros_like(z[1])\n",
    "    # TODO: fill me in so that d se / d z1 is plotted\n",
    "    dse_dz1 = torch.zeros_like(z[1])\n",
    "    ax1.clear()\n",
    "    ax1.set_ylim(-0.7, 0.7)\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_xlabel('Difference between logits $z_1 - z_0$')\n",
    "    ax1.set_title(f'Gradient of loss with repect to $z_1$ when $y_1={y1:.3f}$')\n",
    "\n",
    "    if dokl:\n",
    "        ax1.plot(z[1], dkl_dz1, color='b', label=r'$\\frac{\\partial \\mathrm{KL}}{\\partial z_1}$' +\n",
    "            r'=$\\frac{\\partial \\mathrm{CE}}{\\partial z_1}$')\n",
    "    if dose:\n",
    "        ax1.plot(z[1], dse_dz1, color='r', label=r'$\\frac{\\partial \\mathrm{SE}}{\\partial z_1}$')\n",
    "    ax1.axhline(0, color='gray', linewidth=0.5)\n",
    "    if dokl or dose:\n",
    "        ax1.legend(loc='upper left')\n",
    "\n",
    "rw = Range(min=0.001, max=0.999, step=0.001, value=0.5)\n",
    "bkl = Checkbox('KL', value=True)\n",
    "bce = Checkbox('CE', value=False)\n",
    "bse = Checkbox('SE', value=True)\n",
    "bl1 = Checkbox('L1', value=False)\n",
    "ploss = PlotWidget(compare_loss, y1=rw.prop('value'),\n",
    "                   dokl=bkl.prop('value'), dose=bse.prop('value'),\n",
    "                   doce=bce.prop('value'), dol1=bl1.prop('value'),\n",
    "                   bbox_inches='tight')\n",
    "pgrad = PlotWidget(compare_grad, y1=rw.prop('value'),\n",
    "                   dokl=bkl.prop('value'), dose=bse.prop('value'),\n",
    "                   bbox_inches='tight')\n",
    "show([[show.raw_html('<div>target y<sub>1</sub> = </div>'),\n",
    "                       show.style(flex=12), rw,\n",
    "                       'Include:', bkl, bce, bl1, bse],\n",
    "                      [ploss, pgrad]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c959b4",
   "metadata": {
    "id": "e2c959b4"
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "For part 2 of the homework, proceed to the next notebook."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
